{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week0_V1.ipynb","provenance":[{"file_id":"1RHXVPblVyBgQrOrtyD84inW7jJpP2_H0","timestamp":1627227419165}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SsK70HKKtGEk"},"source":["## Welcome to Week 0!\n","\n","Live sessions during this course will be oriented primarily around:\n","\n","1.   Lecture\n","2.   Programming in [Jupyter notebooks](https://jupyter.org/) like the one you're in now.\n","\n","We will release notebooks on Mondays. Before lecture, you should download the .ipynb file, and open it either locally on your own machine or in Google Colab. It's a good idea to skim the notebook to get a sense for what it covers, but **don't start working on it before lecture**--the idea is for you to starting working on these **in class** (with the instructors and, more importantly, with your classmates).\n","\n","---\n","\n","This week we have some warm-up excercises to go through so that we can all practice using notebooks and some other tools that will be used throughout the course.\n","\n","*   Google Colab is a tool for editing and running Jupyter notebooks using Google's infrastructure. For most of you, using Colab to edit and run notebooks will make your life easier, especially after week 5 of the course.\n","*   We're asking you to do Week 0's assignment (this one) in Colab, but after today you **aren't required to use it**.\n"]},{"cell_type":"markdown","metadata":{"id":"EEmebwjevCxD"},"source":["### Task 1 -- Mounting your Google Drive and loading in the data\n","*   Make a folder in Google Drive where you can put content for the course. Then\n","download the .ipynb file released in Canvas, along with any accompanying data (this week the data is `time_series_covid_19_confirmed.csv`).\n","*   Upload these to your Google Drive folder, and open the .ipynb file in Colab:\n","\n","  <img src='https://drive.google.com/uc?id=1qIfHxtBqfIhnRblvBQMZKAIJrS8ne4Ik' width=\"400\">\n"]},{"cell_type":"markdown","metadata":{"id":"F5MwJ1zM5AhV"},"source":["Now connect this Colab notebook to your Google Drive and load in the COVID data. There are [several ways to do this](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=c2W5A2px3doP), but just follow along with the two options we present below:"]},{"cell_type":"code","metadata":{"id":"0y-Hy-cPL-pH"},"source":["import pandas as pd\n","# use this to wrangle .csv files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmBPUvjoLDg3"},"source":["\n","---\n","\n","**Option 1: mounting locally**"]},{"cell_type":"code","metadata":{"id":"Mqah54vN8CVB"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NliK7yTn8LMn"},"source":["^^ This mounts your Google Drive at the location */content/drive* on the virtual machine running this notebook."]},{"cell_type":"code","metadata":{"id":"sRi98Qrk97eR"},"source":["# my copy of the COVID data is located in my drive at Datasets/week_0/time_series_covid_19_confirmed.csv\n","data = pd.read_csv('/content/drive/My Drive/Datasets/week_0/time_series_covid_19_confirmed.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7J40NtEMnvU"},"source":["\n","---\n","**Option 2: use the PyDrive library**"]},{"cell_type":"code","metadata":{"id":"_GlfTo5zE2ba"},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HT1yuyN5zJ19"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mifumPuu6soS"},"source":["Get the unique identifier for the file containing COVID data in your Google Drive: \n","\n","1.   Right-click on the name of the file \n","2.   Click \"Get link\"\n","3.   Copy the characters between `d/` and the following slash\n","4.   Paste them into the dictionary element of the call to `drive.CreateFile()` below."]},{"cell_type":"code","metadata":{"id":"mb5xkL1QzPYg"},"source":["downloaded = drive.CreateFile({'id':'1JhOQPocfG8UzzpTu5GYccBzRE7GV5neE'})\n","downloaded.GetContentFile('time_series_covid_19_confirmed.csv') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVIEJqb7N0K0"},"source":["^^ This should have **created** a file called `time_series_covid_19_confirmed.csv` in the current directory on the virtual machine. Now you can load it from there:"]},{"cell_type":"code","metadata":{"id":"RGRlpvWjOdAr"},"source":["data = pd.read_csv('time_series_covid_19_confirmed.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KuKdLYyKPaEf"},"source":["\n","\n","---\n","\n","### Task 2 -- Get familiar with the data\n"]},{"cell_type":"code","metadata":{"id":"GsmBMe9c5tjm"},"source":["import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"qSqsKMSJQDDN","executionInfo":{"status":"ok","timestamp":1627226744325,"user_tz":420,"elapsed":163,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}},"outputId":"5a684b1b-31d8-4c53-964d-540adbd76bc3"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Province/State</th>\n","      <th>Country/Region</th>\n","      <th>Lat</th>\n","      <th>Long</th>\n","      <th>1/22/20</th>\n","      <th>1/23/20</th>\n","      <th>1/24/20</th>\n","      <th>1/25/20</th>\n","      <th>1/26/20</th>\n","      <th>1/27/20</th>\n","      <th>1/28/20</th>\n","      <th>1/29/20</th>\n","      <th>1/30/20</th>\n","      <th>1/31/20</th>\n","      <th>2/1/20</th>\n","      <th>2/2/20</th>\n","      <th>2/3/20</th>\n","      <th>2/4/20</th>\n","      <th>2/5/20</th>\n","      <th>2/6/20</th>\n","      <th>2/7/20</th>\n","      <th>2/8/20</th>\n","      <th>2/9/20</th>\n","      <th>2/10/20</th>\n","      <th>2/11/20</th>\n","      <th>2/12/20</th>\n","      <th>2/13/20</th>\n","      <th>2/14/20</th>\n","      <th>2/15/20</th>\n","      <th>2/16/20</th>\n","      <th>2/17/20</th>\n","      <th>2/18/20</th>\n","      <th>2/19/20</th>\n","      <th>2/20/20</th>\n","      <th>2/21/20</th>\n","      <th>2/22/20</th>\n","      <th>2/23/20</th>\n","      <th>2/24/20</th>\n","      <th>2/25/20</th>\n","      <th>2/26/20</th>\n","      <th>...</th>\n","      <th>7/21/20</th>\n","      <th>7/22/20</th>\n","      <th>7/23/20</th>\n","      <th>7/24/20</th>\n","      <th>7/25/20</th>\n","      <th>7/26/20</th>\n","      <th>7/27/20</th>\n","      <th>7/28/20</th>\n","      <th>7/29/20</th>\n","      <th>7/30/20</th>\n","      <th>7/31/20</th>\n","      <th>8/1/20</th>\n","      <th>8/2/20</th>\n","      <th>8/3/20</th>\n","      <th>8/4/20</th>\n","      <th>8/5/20</th>\n","      <th>8/6/20</th>\n","      <th>8/7/20</th>\n","      <th>8/8/20</th>\n","      <th>8/9/20</th>\n","      <th>8/10/20</th>\n","      <th>8/11/20</th>\n","      <th>8/12/20</th>\n","      <th>8/13/20</th>\n","      <th>8/14/20</th>\n","      <th>8/15/20</th>\n","      <th>8/16/20</th>\n","      <th>8/17/20</th>\n","      <th>8/18/20</th>\n","      <th>8/19/20</th>\n","      <th>8/20/20</th>\n","      <th>8/21/20</th>\n","      <th>8/22/20</th>\n","      <th>8/23/20</th>\n","      <th>8/24/20</th>\n","      <th>8/25/20</th>\n","      <th>8/26/20</th>\n","      <th>8/27/20</th>\n","      <th>8/28/20</th>\n","      <th>8/29/20</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>Afghanistan</td>\n","      <td>33.93911</td>\n","      <td>67.709953</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>35615</td>\n","      <td>35727</td>\n","      <td>35928</td>\n","      <td>35981</td>\n","      <td>36036</td>\n","      <td>36157</td>\n","      <td>36263</td>\n","      <td>36368</td>\n","      <td>36471</td>\n","      <td>36542</td>\n","      <td>36675</td>\n","      <td>36710</td>\n","      <td>36710</td>\n","      <td>36747</td>\n","      <td>36782</td>\n","      <td>36829</td>\n","      <td>36896</td>\n","      <td>37015</td>\n","      <td>37054</td>\n","      <td>37054</td>\n","      <td>37162</td>\n","      <td>37269</td>\n","      <td>37345</td>\n","      <td>37424</td>\n","      <td>37431</td>\n","      <td>37551</td>\n","      <td>37596</td>\n","      <td>37599</td>\n","      <td>37599</td>\n","      <td>37599</td>\n","      <td>37856</td>\n","      <td>37894</td>\n","      <td>37953</td>\n","      <td>37999</td>\n","      <td>38054</td>\n","      <td>38070</td>\n","      <td>38113</td>\n","      <td>38129</td>\n","      <td>38140</td>\n","      <td>38143</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>Albania</td>\n","      <td>41.15330</td>\n","      <td>20.168300</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>4290</td>\n","      <td>4358</td>\n","      <td>4466</td>\n","      <td>4570</td>\n","      <td>4637</td>\n","      <td>4763</td>\n","      <td>4880</td>\n","      <td>4997</td>\n","      <td>5105</td>\n","      <td>5197</td>\n","      <td>5276</td>\n","      <td>5396</td>\n","      <td>5519</td>\n","      <td>5620</td>\n","      <td>5750</td>\n","      <td>5889</td>\n","      <td>6016</td>\n","      <td>6151</td>\n","      <td>6275</td>\n","      <td>6411</td>\n","      <td>6536</td>\n","      <td>6676</td>\n","      <td>6817</td>\n","      <td>6971</td>\n","      <td>7117</td>\n","      <td>7260</td>\n","      <td>7380</td>\n","      <td>7499</td>\n","      <td>7654</td>\n","      <td>7812</td>\n","      <td>7967</td>\n","      <td>8119</td>\n","      <td>8275</td>\n","      <td>8427</td>\n","      <td>8605</td>\n","      <td>8759</td>\n","      <td>8927</td>\n","      <td>9083</td>\n","      <td>9195</td>\n","      <td>9279</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>Algeria</td>\n","      <td>28.03390</td>\n","      <td>1.659600</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>24278</td>\n","      <td>24872</td>\n","      <td>25484</td>\n","      <td>26159</td>\n","      <td>26764</td>\n","      <td>27357</td>\n","      <td>27973</td>\n","      <td>28615</td>\n","      <td>29229</td>\n","      <td>29831</td>\n","      <td>30394</td>\n","      <td>30950</td>\n","      <td>31465</td>\n","      <td>31972</td>\n","      <td>32504</td>\n","      <td>33055</td>\n","      <td>33626</td>\n","      <td>34155</td>\n","      <td>34693</td>\n","      <td>35160</td>\n","      <td>35712</td>\n","      <td>36204</td>\n","      <td>36699</td>\n","      <td>37187</td>\n","      <td>37664</td>\n","      <td>38133</td>\n","      <td>38583</td>\n","      <td>39025</td>\n","      <td>39444</td>\n","      <td>39847</td>\n","      <td>40258</td>\n","      <td>40667</td>\n","      <td>41068</td>\n","      <td>41460</td>\n","      <td>41858</td>\n","      <td>42228</td>\n","      <td>42619</td>\n","      <td>43016</td>\n","      <td>43403</td>\n","      <td>43781</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>Andorra</td>\n","      <td>42.50630</td>\n","      <td>1.521800</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>884</td>\n","      <td>889</td>\n","      <td>889</td>\n","      <td>897</td>\n","      <td>897</td>\n","      <td>897</td>\n","      <td>907</td>\n","      <td>907</td>\n","      <td>918</td>\n","      <td>922</td>\n","      <td>925</td>\n","      <td>925</td>\n","      <td>925</td>\n","      <td>937</td>\n","      <td>939</td>\n","      <td>939</td>\n","      <td>944</td>\n","      <td>955</td>\n","      <td>955</td>\n","      <td>955</td>\n","      <td>963</td>\n","      <td>963</td>\n","      <td>977</td>\n","      <td>981</td>\n","      <td>989</td>\n","      <td>989</td>\n","      <td>989</td>\n","      <td>1005</td>\n","      <td>1005</td>\n","      <td>1024</td>\n","      <td>1024</td>\n","      <td>1045</td>\n","      <td>1045</td>\n","      <td>1045</td>\n","      <td>1060</td>\n","      <td>1060</td>\n","      <td>1098</td>\n","      <td>1098</td>\n","      <td>1124</td>\n","      <td>1124</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>Angola</td>\n","      <td>-11.20270</td>\n","      <td>17.873900</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>779</td>\n","      <td>812</td>\n","      <td>851</td>\n","      <td>880</td>\n","      <td>916</td>\n","      <td>932</td>\n","      <td>950</td>\n","      <td>1000</td>\n","      <td>1078</td>\n","      <td>1109</td>\n","      <td>1148</td>\n","      <td>1164</td>\n","      <td>1199</td>\n","      <td>1280</td>\n","      <td>1344</td>\n","      <td>1395</td>\n","      <td>1483</td>\n","      <td>1538</td>\n","      <td>1572</td>\n","      <td>1672</td>\n","      <td>1679</td>\n","      <td>1735</td>\n","      <td>1762</td>\n","      <td>1815</td>\n","      <td>1852</td>\n","      <td>1879</td>\n","      <td>1906</td>\n","      <td>1935</td>\n","      <td>1966</td>\n","      <td>2015</td>\n","      <td>2044</td>\n","      <td>2068</td>\n","      <td>2134</td>\n","      <td>2171</td>\n","      <td>2222</td>\n","      <td>2283</td>\n","      <td>2332</td>\n","      <td>2415</td>\n","      <td>2471</td>\n","      <td>2551</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 225 columns</p>\n","</div>"],"text/plain":["  Province/State Country/Region       Lat  ...  8/27/20  8/28/20  8/29/20\n","0            NaN    Afghanistan  33.93911  ...    38129    38140    38143\n","1            NaN        Albania  41.15330  ...     9083     9195     9279\n","2            NaN        Algeria  28.03390  ...    43016    43403    43781\n","3            NaN        Andorra  42.50630  ...     1098     1124     1124\n","4            NaN         Angola -11.20270  ...     2415     2471     2551\n","\n","[5 rows x 225 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ou2HjkwBQLrm"},"source":["Write a few sentences describing what you notice about this data:\n","\n","[Your response here]\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GQ0HMQcHuTLk"},"source":["Subsample the data so that it only uses 50 countries and the first 100 days"]},{"cell_type":"code","metadata":{"id":"wIgLJC0eUtyI","executionInfo":{"status":"ok","timestamp":1627227656813,"user_tz":420,"elapsed":112,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["# [YOUR CODE HERE]"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WF3qSqfazYwj"},"source":["Take a random subsample of 5 countries and plot infections vs time (you can report time as the number of days after January 22, 2020)"]},{"cell_type":"code","metadata":{"id":"3PdoAfP7UxiD","executionInfo":{"status":"ok","timestamp":1627227666156,"user_tz":420,"elapsed":107,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["# [YOUR CODE HERE]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qgfa8HxD3xxw"},"source":["### Task 3 -- Set up a regression problem based on latitude, longitude, and date\n","Okay, so now we're going to see if the combination of latitude, longitude, and date can be used to accurately predict the number of infections in this dataset.\n","\n","Start by creating two matrices $\\mathbf{X}$ and $\\mathbf{Y}$, where $\\mathbf{X}$ holds the [latitude, longitude, date] data and $\\mathbf{Y}$ holds the infection data. $\\mathbf{X}$ will have shape $k \\times 3$ and $\\mathbf{Y}$ should have shape $k \\times 1$. What is the value $k$, based on the size of the subsample from the full dataset that we've taken?\n"]},{"cell_type":"markdown","metadata":{"id":"OxrDIMsfVL2h"},"source":["k = [YOUR ANSWER HERE]"]},{"cell_type":"markdown","metadata":{"id":"9BY1rMHeVRUd"},"source":["Create the matrices $\\mathbf{X}$ and $\\mathbf{Y}$ below:"]},{"cell_type":"code","metadata":{"id":"GRmAGoFsVafv","executionInfo":{"status":"ok","timestamp":1627228397674,"user_tz":420,"elapsed":151,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["X = None\n","Y = None\n","# [YOUR CODE HERE]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qVL18ajK9iZd"},"source":["Make a plot with 3 subplots, one for each of the independent variables (latitude, longitude, and date). Plot the data, displaying the independent variable on the x axis and the dependent variable (infections) on the y axis"]},{"cell_type":"code","metadata":{"id":"e_eW0gHA-NEN","executionInfo":{"status":"ok","timestamp":1627227870075,"user_tz":420,"elapsed":141,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["# [YOUR CODE HERE]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7ffGAgn__nd"},"source":["Discuss with your classmates in your breakout room what you notice about this data. Are there other ways you might try to visualize it to uncover some structure? Does this data look like a good candidate for fitting a linear model?\n","\n","[Your answer here]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0HQMSndiBCQA"},"source":["Now split the data randomly into training and test sets. Make the training set 70% of the data and the test set the remaining 30%. You could do this manually, but we'll use the `train_test_split` function from the machine learning library [scikit-learn](https://scikit-learn.org/stable/)."]},{"cell_type":"code","metadata":{"id":"1d9l2gD4Bwlp"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v0mGj3pFCVsw"},"source":["^^ What is the `random_state` parameter doing? Read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) on `train_test_split` to find out. \n","\n","Note: This week is a good time to get very familiar with scikit-learn, if you haven't already. We will be using it a fair amount in this course and it's a great resource for applying machine learning models."]},{"cell_type":"markdown","metadata":{"id":"qH5SZjxBDnR-"},"source":["### Task 4 -- Apply a polynomial regression of degree 3 to this data"]},{"cell_type":"markdown","metadata":{"id":"1tZq9YwSEKY2"},"source":["You could do this manually using concepts we will cover next week, but for now let's use scikit-learn's `PolynomialFeatures` and `LinearRegression` modules."]},{"cell_type":"code","metadata":{"id":"C2OvjhEsEGzT"},"source":["from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","\n","poly_features = PolynomialFeatures(degree=3)\n","X_train_poly = poly_features.fit_transform(X_train)\n","X_test_poly = poly_features.fit_transform(X_test)\n","print(\"New shape of test data=\", np.shape(X_test_poly))\n","\n","lin_regression = LinearRegression()\n","# Fit the model on train data only\n","lin_regression.fit(X_train_poly, Y_train)\n","print(\"The regression coefficients are: \", lin_regression.coef_)\n","print(\"The intercept is\", lin_regression.intercept_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PupQGZGGGLfs"},"source":["Now use the `.predict()` method of the `lin_regression` object above to generate predictions on the test data. Compare the predictions to `Y_test` using a plot."]},{"cell_type":"code","metadata":{"id":"U1IEL9X1Fd26","executionInfo":{"status":"ok","timestamp":1627227962508,"user_tz":420,"elapsed":155,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["# [YOUR CODE HERE]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JsjaPc60IfKN"},"source":["Report the mean squared error of your predictions.\n","\n","The mean squared error is = [YOUR ANSWER HERE]"]},{"cell_type":"markdown","metadata":{"id":"bsXZU4MbJGWe"},"source":["### Task 5 -- Run an experiment identifying the degree of the best-fitting polynomial regression\n","\n","Your job is now to repeat the fitting and prediction steps above, but for polyomials of all orders from 1 to 20. For each fit, compute and save the mean squared error of the predictions.\n","\n"]},{"cell_type":"code","metadata":{"id":"SivORAMXKM40","executionInfo":{"status":"ok","timestamp":1627228082325,"user_tz":420,"elapsed":131,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}}},"source":["# [YOUR CODE HERE]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oEn4sGXLFbC"},"source":["Report the polynomial order that resulted in the best fit. Does this number make sense? Do you think the regression has produced a good model for the data? Discuss with your classmates."]}]}