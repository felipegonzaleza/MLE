{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"week11_pt1_V1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YrT1XbjWQLhW"},"source":["This notebook will demonstrate how to take a trained TensorFlow model and save it as a TFLite model. The TFLite model is then something that can be deployed as part of a web application. (It'll also show you how you can used the tensorflow_datasets library, if you haven't seen that yet). \n","\n","This follows very closely the original Tensorflow Rock-Paper-Scissors TFHub + TFLite tutorial"]},{"cell_type":"markdown","metadata":{"id":"Za8-Nr5k11fh"},"source":["##### Copyright 2018 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","id":"Eq10uEbw0E4l"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oYM61xrTsP5d"},"source":["# Rock, Paper & Scissors with TensorFlow Hub - TFLite"]},{"cell_type":"markdown","metadata":{"id":"xWFpUd1yy3gt"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c06_exercise_rock_paper_scissors_solution.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n","    Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c06_exercise_rock_paper_scissors_solution.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n","    View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"bL54LWCHt5q5"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"dlauq-4FWGZM"},"source":["import os\n","\n","import matplotlib.pylab as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Hub version: \", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmaHHH7Pvmth"},"source":["## Select the Hub/TF2 module to use\n","\n","Hub modules for TF 1.x won't work here, please use one of the selections provided."]},{"cell_type":"code","metadata":{"id":"FlsEcKVeuCnf"},"source":["module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n","handle_base, pixels, FV_SIZE = module_selection\n","MODULE_HANDLE = \"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {} and output dimension {}\".format(\n","  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYUsgwCBv87A"},"source":["## Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"8nqVX3KYwGPh"},"source":["Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the rock, paper and scissors dataset.\n","\n","This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"]},{"cell_type":"code","metadata":{"id":"jGvpkDj4wBup"},"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YkF4Boe5wN7N"},"source":["The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n","\n","Since `\"rock_paper_scissors\"` doesn't define standard splits, use the subsplit feature to divide it into (train, validation, test) with 80%, 10%, 10% of the data respectively."]},{"cell_type":"code","metadata":{"id":"SQ9xK9F2wGD8"},"source":["splits, info = tfds.load('rock_paper_scissors', with_info=True, as_supervised=True, split = ['train[:80%]','train[80%:90%]','train[90%:]'])\n","\n","\n","(train_examples, validation_examples, test_examples) = splits\n","\n","num_examples = info.splits['train'].num_examples\n","num_classes = info.features['label'].num_classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pmXQYXNWwf19"},"source":["### Format the Data\n","\n","Use the `tf.image` module to format the images for the task.\n","\n","Resize the images to a fixes input size, and rescale the input channels"]},{"cell_type":"code","metadata":{"id":"y7UyXblSwkUS"},"source":["def format_image(image, label):\n","  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n","  return  image, label\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1nrDR8CnwrVk"},"source":["Now shuffle and batch the data\n"]},{"cell_type":"code","metadata":{"id":"zAEUG7vawxLm"},"source":["BATCH_SIZE = 32 #@param {type:\"integer\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHEC9mbswxvM"},"source":["train_batches = train_examples.shuffle(num_examples // 4).batch(BATCH_SIZE).map(format_image).prefetch(1)\n","validation_batches = validation_examples.batch(BATCH_SIZE).map(format_image).prefetch(1)\n","test_batches = test_examples.batch(1).map(format_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghQhZjgEw1cK"},"source":["Inspect a batch"]},{"cell_type":"code","metadata":{"id":"gz0xsMCjwx54"},"source":["for image_batch, label_batch in train_batches.take(1):\n","  pass\n","\n","image_batch.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FS_gVStowW3G"},"source":["## Defining the model\n","\n","All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n","\n","For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."]},{"cell_type":"code","metadata":{"id":"RaJW3XrPyFiF"},"source":["do_fine_tuning = True #@param {type:\"boolean\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50FYNIb1dmJH"},"source":["print(\"Building model with\", MODULE_HANDLE)\n","model = tf.keras.Sequential([\n","    hub.KerasLayer(MODULE_HANDLE,\n","                   input_shape=IMAGE_SIZE + (3, ), \n","                   output_shape=[FV_SIZE],\n","                   trainable=do_fine_tuning),\n","    tf.keras.layers.Dense(num_classes)\n","])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u2e5WupIw2N2"},"source":["## Training the model"]},{"cell_type":"code","metadata":{"id":"9f3yBUvkd_VJ"},"source":["if do_fine_tuning:\n","  model.compile(\n","    optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9), \n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'])\n","else:\n","  model.compile(\n","    optimizer='adam', \n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_YKX2Qnfg6x"},"source":["EPOCHS = 5\n","hist = model.fit(train_batches,\n","                    epochs=EPOCHS,\n","                    validation_data=validation_batches)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_psFoTeLpHU"},"source":["## Export the model"]},{"cell_type":"code","metadata":{"id":"XaSb5nVzHcVv"},"source":["RPS_SAVED_MODEL = \"rps_saved_model\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfbyvF_q31A4"},"source":["...If in Colab..."]},{"cell_type":"code","metadata":{"id":"QtOJ1xmi3zlr"},"source":["#Connect to google drive and save model\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Err-zsEC4J8_"},"source":["# CHANGE THIS TO WHEREVER YOU WANT TO SAVE THE MODEL\n","model_save_path = '/content/drive/MyDrive/Live_session_notebooks/week_11/'\n","full_model_save_path = model_save_path + RPS_SAVED_MODEL"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fZqRAg1uz1Nu"},"source":["Export the SavedModel"]},{"cell_type":"code","metadata":{"id":"yJMue5YgnwtN"},"source":["tf.saved_model.save(model, full_model_save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOQF4cOan0SY"},"source":["%%bash -s $full_model_save_path\n","saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FY7QGBgBytwX"},"source":["loaded = tf.saved_model.load(full_model_save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIhPyMISz952"},"source":["print(list(loaded.signatures.keys()))\n","infer = loaded.signatures[\"serving_default\"]\n","print(infer.structured_input_signature)\n","print(infer.structured_outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxLiLC8n0H16"},"source":["## Convert with TFLiteConverter"]},{"cell_type":"code","metadata":{"id":"WmSr2-yZoUhz"},"source":["converter = tf.lite.TFLiteConverter.from_saved_model(full_model_save_path)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","\n","tflite_model = converter.convert()\n","with open(model_save_path + \"converted_model.tflite\", \"wb\") as f:\n","  f.write(tflite_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BbTF6nd1KG2o"},"source":["Test the TFLite model using the Python Interpreter"]},{"cell_type":"code","metadata":{"id":"dg2NkVTmLUdJ"},"source":["# Load TFLite model and allocate tensors.\n","tflite_model_file = model_save_path + 'converted_model.tflite'\n","with open(tflite_model_file, 'rb') as fid:\n","  tflite_model = fid.read()\n","  \n","interpreter = tf.lite.Interpreter(model_content=tflite_model)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snJQVs9JNglv"},"source":["from tqdm import tqdm\n","\n","# Gather results for the randomly sampled test images\n","predictions = []\n","\n","test_labels, test_imgs = [], []\n","for img, label in tqdm(test_batches.take(10)):\n","  interpreter.set_tensor(input_index, img)\n","  interpreter.invoke()\n","  predictions.append(interpreter.get_tensor(output_index))\n","  \n","  test_labels.append(label.numpy()[0])\n","  test_imgs.append(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"YMTWNqPpNiAI"},"source":["#@title Utility functions for plotting\n","# Utilities for plotting\n","\n","class_names = ['rock', 'paper', 'scissors']\n","\n","def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","    \n","  img = np.squeeze(img)\n","\n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  print(type(predicted_label), type(true_label))\n","  if predicted_label == true_label:\n","    color = 'green'\n","  else:\n","    color = 'red'\n","  \n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-lbnicPNkZs"},"source":["#@title Visualize the outputs { run: \"auto\" }\n","index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(index, predictions, test_labels, test_imgs)\n","plt.show()"],"execution_count":null,"outputs":[]}]}