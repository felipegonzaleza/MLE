{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"week5_V1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FN-ViWqqtVFq"},"source":["# Today you are Machine Learning Engineer@ Epic Software Systems, and your task is to develop a new Recommendation System for Opthalmologists (eye doctors)!\n","\n","### Diabetic Retinopathy (DR) is a pathology that impacts patients with Diabetes Mellitus 2, such that vision is compromised. Base paper on Automated classification of diabetic retinopathy:\n","https://ieeexplore.ieee.org/abstract/document/6680633\n","### Diabetic Retinopathy classification using modified AlexNet paper: https://www.sciencedirect.com/science/article/abs/pii/S0045790618334190\n","### Paper available at https://drive.google.com/file/d/1nl5tYA2jJ1Up_malA8uQmvwHu6UH0k-r/view?usp=sharing\n","\n","\n","### Automated classification of DR severity can help streamline the treatment process such that patients with higher severity are seen by the doctor first followed by the less severe patiets. This problem of DR clasification is significant since retinal images are biometrics (unique for each individual) which makes generalized modeling difficult and since 90% of the diabetic population that get imaged each year are have NO DR.\n","\n","### This hard problem can be attacked using the tools of Deep Learning. Today we will show you how to use TensorFlow to construct and train a deep learning model on a small amount of DR data. In the clinic we would like to screen patients with different severity levels of the disease: patients that have NO DR (y=0), vs ones with mild DR (y=1), moderate DR (y=2) and severe DR (y=4). However, in this assignment we're going to make it even easier--the model will just do binary classification: normal images (patients without DR) will be labeled y=0, and those with any amount of DR as y=1.\n","\n","### The purpose of this assignment is to show you the mechanics of using TensorFlow, not to say that what we present is the state-of-the-art in DR classification--far from it. But the ideas we use today are the first steps in an ML pipeline that can get quite-good performance in classifying diabetic retinopathy :)"]},{"cell_type":"markdown","metadata":{"id":"2yeDAkRJue6N"},"source":["### If using Colab, mount your Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV8HKsvDuOi1","executionInfo":{"status":"ok","timestamp":1629748483850,"user_tz":360,"elapsed":20214,"user":{"displayName":"Spencer Kent","photoUrl":"","userId":"07841346171340846448"}},"outputId":"d45880ea-bc11-4ca2-cbfd-46b661b61d18"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LO5Qps8pujZY"},"source":["### Change your working directory to the one containing this notebook"]},{"cell_type":"code","metadata":{"id":"DolSmooVupCf"},"source":["import os\n","os.chdir('/content/drive/MyDrive/Live_session_notebooks/week_5/')  # you'll have to change this to wherever you stored this notebook\n","pwd = os.getcwd()\n","print(pwd)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SIBgaZIbuVDn"},"source":["### Load Tensorflow and (optionally) TensorBoard"]},{"cell_type":"code","metadata":{"id":"IpL2SLYLtVFq"},"source":["%load_ext tensorboard\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlN0YueOtVFr"},"source":["from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C10NEaomtVFr"},"source":["#Load the libraries\n","from datetime import datetime\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xopf7ZgKtVFr"},"source":["# Task 0: Get familiar with the data"]},{"cell_type":"code","metadata":{"id":"LEUW_jHmtVFr"},"source":["#Read the data and split into train and validation\n","from sklearn.model_selection import train_test_split\n","import h5py\n","f = h5py.File('/content/drive/MyDrive/Datasets/week_5/1194_DR_smallimages.h5', 'r')  # this is wherever you stored the data\n","images = f['images']\n","labels = np.array(f['meta'])\n","print(f'Number of images = {len(labels)}')\n","#Plot the image and its label\n","num = 100\n","plt.imshow(images[num])\n","print(f\"This image has DR = {labels[num]}\")\n","print(f\"Maximum pixel value in image = {np.max(images[num])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdrGNQFhtVFs"},"source":["# Task 1: Data Pre-processing: \n","1. Exploratory data analysis (Frequency of labels)\n","2. Normalization of images in [0, 1] range.\n","3. Generation of Training, Test data sets (66/33% split)"]},{"cell_type":"markdown","metadata":{"id":"zhRr_V84v7p-"},"source":["### Exercise: Plot a histogram illustrating the number of images corresponding to each of the 4 DR severity labels"]},{"cell_type":"code","metadata":{"id":"rge9X3kwtVFs"},"source":["### START CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZfxdcWew9n5"},"source":["### Exercise: Normalize the images' pixel values so they fall in the range [0, 1]"]},{"cell_type":"code","metadata":{"id":"-MytDLxftVFs"},"source":["### START CODE HERE ###\n","images_new = None\n","### END CODE HERE ###\n","plt.imshow(images_new[10])\n","print(f\"Maximum pixel value in an image = {np.max(images_new[10])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qbALXo5H0hcM"},"source":["### Exercise: Binarize the class labels. Set up 2 one-hot-encoded columns. Column 0 will contain a 1 for every row where the label is 0. Column 1 will contain a 1 for every row where the label is 1, 2, or 3.\n","\n","### You might be wondering why we don't use a single one-hot-encoded column, since our problem is binary classification. This will become clear in Task 2, when we inspect the AlexNet architecture. \n"]},{"cell_type":"code","metadata":{"id":"duDe7sk7skIw"},"source":["### START CODE HERE ###\n","one_hot_labels = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0eUvLD1JN_Bu"},"source":["### Exercise: Perform a 2/3 - 1/3 train-test split on the data"]},{"cell_type":"code","metadata":{"id":"Jty-CUI0Phiz"},"source":["### START CODE HERE ###\n","def split_data(mat, target, train_ratio):\n","    # mat is a matrix of features, target is a matrix of the classification targets\n","    X_train = None\n","    X_test  = None\n","    Y_train = None\n","    Y_test  = None\n","    return X_train, X_test, Y_train, Y_test\n","\n","# Call the function you just defined to create the training and test data\n","X_train, X_test, Y_train, Y_test = None\n","\n","### END CODE HERE ###\n","# Visualize the distribution of the binarized labels for both the training and test data\n","plt.hist(Y_train[:,1])\n","plt.hist(Y_test[:,1])\n","print(f'X_train.shape = {X_train.shape}')\n","print(f'X_test.shape  = {X_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"usiNL9SotVFs"},"source":["# Task 2: Model Definition, classification and prediction (No regularization)"]},{"cell_type":"markdown","metadata":{"id":"wSGjpe54efCN"},"source":["## AlexNet architecture"]},{"cell_type":"code","metadata":{"id":"5fGMFAqCtVFs"},"source":["# Define the AlexNet model [This is given]\n","#1. Model Definition\n","class AlexNet(Sequential):\n","   def __init__(self, input_shape, num_classes):\n","    super().__init__()\n","\n","    self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n","                    padding= 'valid', activation= 'relu',\n","                    input_shape= input_shape, kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None))\n","    \n","    \n","    self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None)) \n","    \n","\n","    self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None))\n","    \n","\n","    self.add(Flatten())\n","    \n","    self.add(Dense(num_classes, activation= 'softmax'))\n","\n","    self.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txc7-3WxoIic"},"source":["### Since our problem involves binary classification, set `num_classes` to 2"]},{"cell_type":"code","metadata":{"id":"ngTskMERtVFs"},"source":["num_classes = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pMxmDuPl2lM"},"source":["### Exercise: Instantiate the model and summarize its architecture using the `.summary()` method of the model instance."]},{"cell_type":"code","metadata":{"id":"NeGeg_LQtVFs"},"source":["### START CODE HERE ###\n","model = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jFJdmnVtsw5T"},"source":["Discuss with your classmates your interpretation of this summary, what do these numbers and names represent (it's okay to speculate)"]},{"cell_type":"markdown","metadata":{"id":"zGAE8oJJp6Vf"},"source":["\n","### Exercise: Train the model, using its `.fit()` method. If you want to use TensorBoard to visualize how its properties evolve over the training epochs, you'll have to create a log directory and employ a TensorBoard callback. We include code for creating the callback below, but you'll have to pass it in as a parameter of the `.fit()` method. \n","### In training the model, set aside 20% of the data as a validation set. Use a batch size of 20. Set the output verbosity to 1. Train the model for 40 epochs."]},{"cell_type":"code","metadata":{"id":"V3ceEeVZ2-7B"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from helper_functions_for_week5 import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ipP4sartVFs"},"source":["##### Comment the following two lines if you don't want to use tensorboard\n","logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n","#####\n","\n","### START CODE HERE ####\n","training_history = None\n","### END CODE HERE ###\n","print(\"Average test loss: \", np.average(training_history.history['loss']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"virBzWKumZ3l"},"source":["### Exercise: Display loss and accuracy for both the training and validation data. You should find the provided functions in `helper_functions_for_week5.py` useful. "]},{"cell_type":"code","metadata":{"id":"pHk5rvpitVFs"},"source":["### START CODE HERE ###\n","\n","### END CODE HERE ###\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUV7fl2x3rBU"},"source":["# if you used tensorboard callbacks, try launching tensorboard to view the logs:\n","# If developing locally: `tensorboard --logdir <THIS_DIRECTORY>/logs\n","# If developing on Colab: `%tensorboard --logdir logs`"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJqZxyJwBlol"},"source":["### Exercise: Generate predictions with the test data"]},{"cell_type":"code","metadata":{"id":"tKm9CzwvtVFs"},"source":["### START CODE HERE ###\n","prediction_values = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpO3gXbfCH8F"},"source":["### Exercise: Evaluate the predictions against the Number 1 column of `Y_test`"]},{"cell_type":"code","metadata":{"id":"DYE3vbX0tVFs"},"source":["from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,precision_score,recall_score\n","### START CODE HERE ###\n","# Import the necessary functions from sklearn.metrics\n","print(f'Accuracy = ')\n","print(f'F1 = ')\n","print(f'Precision = ')\n","print(f'Recall = ')\n","# Display the confusion matrix\n","print('Confusion matrix =')\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nzN4iffuJA7"},"source":["What do you notice about the performance of this model, especially as it relates to the difference between train and validation accuracy?"]},{"cell_type":"markdown","metadata":{"id":"dpMVM8vqtVFs"},"source":["### Next, visualize the activations.\n","Source: https://www.kaggle.com/amarjeet007/visualize-cnn-with-keras"]},{"cell_type":"markdown","metadata":{"id":"aYavRekWIoOF"},"source":["### Exercise: Extract the activations for each layer in our AlexNet model"]},{"cell_type":"code","metadata":{"id":"X0pZ_NFHtVFs"},"source":["### START CODE HERE ###\n","# Use a list comprehension to extract the output of each layer in the model\n","layer_outputs = None\n","# Define a new model with the same input shape as the original model \n","# and layer_outputs as its outputs\n","activation_model = None\n","# Get all the activations by calling the predict() method on the number 10 image \n","# in X_train. Make sure to reshape the image so it has a new 0 axis of length 1.\n","activations = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kTLUUg8FNNqW"},"source":["### Exercise: Display the first 64 activations of the second model layer (layer index 1) in an 8 x 8 grid. Again, the helper functions are your friends."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"1xvbj75GtVFs"},"source":["### START CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2MHYr_JQPvp"},"source":["### Exercise: Display the first 64 activations of the 11th model layer (layer index 10) in an 8 x 8 grid"]},{"cell_type":"code","metadata":{"id":"y161bAR_tVFs"},"source":["### START CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5gkWuOb9tVFs"},"source":["# Comment on the activated feature maps for early layers to later layers. What patterns do you observe?"]},{"cell_type":"markdown","metadata":{"id":"rYBVyTXYtVFt"},"source":["# Task 3: Regularization by Data Augmentation [Instructor Led]"]},{"cell_type":"markdown","metadata":{"id":"3Ha5ruYFQ0nC"},"source":["## We can regularize our model (and, in doing so, hopefully improve it) by augmenting our image data. Image augmentation includes transformations such as rotation, translation, reflection, shearing, and color permutation. TensorFlow provides the ImageDataGenerator class to perform image augmentation in memory; by default, your local storage won't save the newly generated images."]},{"cell_type":"code","metadata":{"id":"QRofVa3mtVFt"},"source":["# Create a Data Generator\n","data_gen_args = dict(None) # add in the desired parameters of an ImageDataGenerator \n","image_datagen = ImageDataGenerator(**data_gen_args)\n","\n","image_datagen.fit(X_train)\n","BATCH_SIZE = X_train.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRplxbhDRHb2"},"source":["### Initialize data generator for training/validation and test data sets"]},{"cell_type":"code","metadata":{"id":"WlloVtHqtVFt"},"source":["train_generator = image_datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE)\n","test_generator = image_datagen.flow(X_test, Y_test, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-vyWwv2RQzX"},"source":["### Import libraries and set useful parameters"]},{"cell_type":"code","metadata":{"id":"ltf7nWcM5_29"},"source":["seed = 0\n","aug_batch_size = 6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kmJ9PThctVFt"},"source":["## Step 1: Understanding the data augmentation process\n","Images are randomly generated with the options provided in the image data generator"]},{"cell_type":"code","metadata":{"id":"-lHj0f0RtVFt"},"source":["for e in range(5):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in image_datagen.flow(X_train, Y_train, batch_size=aug_batch_size):\n","        print(x_batch.shape)\n","        for i in range(0, aug_batch_size):\n","            plt.subplot(330+1 + i)\n","            plt.imshow(x_batch[i], cmap=plt.get_cmap('gray'))\n","        \n","\n","        plt.show()\n","        print(y_batch)\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJGi7-LDtVFt"},"source":["## Step 2: Using augmented data to Train the model\n","### Visualize using tensorboard"]},{"cell_type":"markdown","metadata":{"id":"SXcTSbcmTgCi"},"source":["### Method 1: Iterate through randomized `(X, y)` batches generated by `train_generator` and fit AlexNet to each one"]},{"cell_type":"code","metadata":{"id":"aB8EwEUOtVFt"},"source":["model_reg = AlexNet((np.shape(X_train)[1],np.shape(X_train)[2], 3), num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8o2IfhXtVFt"},"source":["#Method 1: Randomized batches\n","EPOCHS = 40\n","reg_history_loss = []\n","reg_history_vloss = []\n","reg_history_accuracy = []\n","reg_history_val_accuracy = []\n","# Start training\n","for e in range(EPOCHS):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in train_generator:\n","        reg_hist = (model_reg.fit(x_batch, y_batch,validation_split=0.2, verbose=1))\n","        batches += 1\n","        reg_history_loss.append(reg_hist.history['loss'])\n","        reg_history_vloss.append(reg_hist.history['val_loss'])\n","        reg_history_accuracy.append(reg_hist.history['accuracy'])\n","        reg_history_val_accuracy.append(reg_hist.history['val_accuracy'])\n","        if batches >= len(X_train) / BATCH_SIZE:\n","            # we need to break the loop by hand because\n","            # the generator loops indefinitely\n","            break   \n","\n","\n","#^ If you have issues with your Colab instance running out of memory, you may have to delete some \n","#  previously-created variables such as `model` object holding the unregularized version of AlexNet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajwUrwDwSy5D"},"source":["### Plot the losses and accuracies for both training and validation data"]},{"cell_type":"code","metadata":{"id":"S5fiVcXrtVFt"},"source":["#Print the loss and accuracies\n","print_loss_history({'loss': reg_history_loss, 'val_loss': reg_history_vloss})\n","print_loss_history({'loss': reg_history_loss, 'val_loss': reg_history_vloss}, logscale=True)\n","print_accuracy_history({'accuracy': reg_history_accuracy, 'val_accuracy': reg_history_val_accuracy})\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCZuZWLQTKGL"},"source":["### Method 2: Pass `train_generator` into the model's `fit()` method directly and abstract away the looping"]},{"cell_type":"code","metadata":{"id":"AVqL13L8tVFt"},"source":["#Method 2\n","model_reg_2 = AlexNet((np.shape(X_train)[1],np.shape(X_train)[2], 3), num_classes)\n","reg_history = model_reg_2.fit(\n","    train_generator,\n","    steps_per_epoch=50,\n","    verbose=1, \n","    epochs=40,\n","#    callbacks=[tensorboard_callback]\n",")\n","\n","print(\"Average test loss: \", np.average(reg_history.history['loss']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qonk1BfaC0iX"},"source":["print_loss_history(reg_history.history)\n","print_loss_history(reg_history.history, logscale=True)\n","print_loss_accuracy(reg_history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8T3mfLio9kw"},"source":["Now we can save the whole trained model to disk:"]},{"cell_type":"code","metadata":{"id":"7_lZqgKrtVFt"},"source":["model_reg_dir = \"reg_model.h5\"\n","model_reg.save(model_reg_dir)  # or model_reg_2 if that's the one you trained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"JwnAFvlLtVFt"},"source":["# %tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCIxpNPitVFt"},"source":["# Task 4: Evaluate the Regularized Model and Report Results"]},{"cell_type":"markdown","metadata":{"id":"VEUFudHjUTtg"},"source":["### Exercise: Compute the evaluation metrics"]},{"cell_type":"code","metadata":{"id":"qVzPv2u3tVFt"},"source":["### START CODE HERE ###\n","print(f'Accuracy = ')\n","print(f'F1 = ')\n","print(f'Precision = ')\n","print(f'Recall = ')\n","print('Confusion matrix = ')\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vKsAAJ2tVFt"},"source":["# Visualize activations from early layers after regularization and report results"]},{"cell_type":"code","metadata":{"id":"zxevfDmptVFt"},"source":["### START CODE HERE ###\n","activations = None\n","### END CODE HERE ##\n","display_activation(activations, 8, 8, 1) #For layer 2\n","display_activation(activations, 8, 8, 11) #For layer 10"],"execution_count":null,"outputs":[]}]}